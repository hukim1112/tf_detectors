{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4693f28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b199d6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from config.path import PATH # config/path.py to manage your dataset paths\n",
    "coco_path = PATH[\"COCO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4260dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "  except RuntimeError as e:\n",
    "    # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cffbaba",
   "metadata": {},
   "source": [
    "import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427b9335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.ssd import SSDDataset\n",
    "from models.SSD import SSD300\n",
    "from models.RetinaNet import RetinaNet\n",
    "from utils.visualize import visualize_detections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c15b0e2",
   "metadata": {},
   "source": [
    "### Load COCO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146e0d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = f\"{coco_path}/images/train2017\"\n",
    "annotation_path = f\"{coco_path}/annotations/large_pedestrian_train.json\"\n",
    "train_dataset = SSDDataset(image_path, annotation_path, num_examples=50, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9d07b5",
   "metadata": {},
   "source": [
    "Visualize a single data sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80a5de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, boxes, classes = train_dataset.get_item(train_dataset.image_ids[0])\n",
    "visualize_detections(image, boxes, classes, tf.ones_like(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a9d594",
   "metadata": {},
   "source": [
    "### Load your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867e0f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSD300\n",
    "num_classes = train_dataset.num_classes()\n",
    "model = SSD300(num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17689139",
   "metadata": {},
   "source": [
    "### Load data pipeline\n",
    "\n",
    "Each sample which consist of (image, bounding boxes, classes), will be converted into image, ground truths of anchors (N, anchor, 5). 5 is [dx,dy,dw,dh,class_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8d4d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfds = train_dataset.load_tfds(batch_size=1, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c444a2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = next(iter(train_tfds))\n",
    "for item in items:\n",
    "    print(item.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6b5bfb",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fb6fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer)\n",
    "model.fit(train_tfds, epochs=5, verbose=1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7653c7a",
   "metadata": {},
   "source": [
    "### load a pretrained model and visualize inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59283968",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_dir = \"experiments/large_Pedestrian_SSD/20220714-171249/\"\n",
    "latest_checkpoint = tf.train.latest_checkpoint(weights_dir)\n",
    "model.load_weights(latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4129da",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = items[0]\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a7ec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model = model.inference(confidence_threshold=0.3)\n",
    "detections = inference_model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054cc6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.visualize import visualize_inference\n",
    "visualize_inference(images[0], train_dataset.labels, detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceb37f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
